{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils.config \n",
    "import pprint\n",
    "import torch\n",
    "\n",
    "env = UnityEnvironment(file_name=\"Tennis_Linux/Tennis.x86\", no_graphics=True)\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create instance of agent\n",
    "\n",
    "Agent's hyperparameters are saved and loaded from config.py file in utils folder. Current values are result of selected after hyperparameter tuing. But you can try different hyperparameter values if you want.\n",
    "\n",
    "If you just want to see the trained agent jump to cell 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent with following hyperparameter values:\n",
      "{'action_size': 2,\n",
      " 'agent_name': 'MADDPG',\n",
      " 'batch_size': 128,\n",
      " 'buffer_size': 1000000,\n",
      " 'fc1_units': 256,\n",
      " 'fc2_units': 128,\n",
      " 'gamma': 0.99,\n",
      " 'lr_actor': 0.001,\n",
      " 'lr_critic': 0.001,\n",
      " 'n_agents': 2,\n",
      " 'random_seed': 0,\n",
      " 'state_size': 24,\n",
      " 'tau': 0.06,\n",
      " 'weight_decay': 0}\n"
     ]
    }
   ],
   "source": [
    "#from agents.maddpg import MADDPG\n",
    "from agents.maddpg_agent import MADDPG\n",
    "\n",
    "# Load parameters from file\n",
    "params = utils.config.HYPERPARAMS['Tennis1']\n",
    "\n",
    "# Create agent instance\n",
    "agent = MADDPG(params['agent'])\n",
    "print(\"Created agent with following hyperparameter values:\")\n",
    "pprint.pprint(params['agent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train an agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.002000\n",
      "Episode 200\tAverage Score: 0.011000\n",
      "Episode 274\tAverage Score: 0.030000\n",
      "Environment solved in 174 episodes!\tAverage Score: 0.03\n"
     ]
    }
   ],
   "source": [
    "# Reset and set environment to training mode\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# Maximum number of training episodes\n",
    "n_episodes = params['n_episodes']\n",
    "\n",
    "# List containing scores from each episode\n",
    "scores = []\n",
    "\n",
    "# Store last 100 scores\n",
    "scores_window = deque(maxlen=params['scores_window_size'])\n",
    "\n",
    "# Filename string\n",
    "filename = \"{:s}_lra{:.0E}_lrc{:.0E}_batch{:d}_fc:{:d}:{:d}_solved{:d}\"\n",
    "\n",
    "# Train loop\n",
    "for i_episode in range(1, n_episodes+1):\n",
    "    # Reset environment\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "    # Observe current state\n",
    "    states = env_info.vector_observations\n",
    "\n",
    "    # Reset score\n",
    "    agent_scores = np.zeros(num_agents)\n",
    "\n",
    "    # Loop each episode\n",
    "    while True:\n",
    "\n",
    "        # Select action \n",
    "        actions = agent.act(states, add_noise=True)\n",
    "        #print(actions)\n",
    "\n",
    "        # Take action\n",
    "        env_info = env.step(actions)[brain_name]\n",
    "\n",
    "        # Get next state, reward and done\n",
    "        next_states = env_info.vector_observations\n",
    "        rewards = env_info.rewards\n",
    "        dones = env_info.local_done\n",
    "\n",
    "        # Store experience and learn\n",
    "        agent.step(states, actions, rewards, next_states, dones)\n",
    "\n",
    "        # State transition\n",
    "        states = next_states\n",
    "\n",
    "        # Update total score\n",
    "        agent_scores += rewards\n",
    "        \n",
    "        # Exit loop if episode finished\n",
    "        if np.any(dones):                                  \n",
    "            break\n",
    "            \n",
    "    # Save most recent score\n",
    "    scores_window.append(np.max(agent_scores))\n",
    "    scores.append([np.max(agent_scores), np.mean(scores_window)])\n",
    "\n",
    "    # Decay epsilon\n",
    "    #epsilon = max(params['epsilon_final'], params['epsilon_decay']*epsilon)\n",
    "\n",
    "    # Print learning progress\n",
    "    print('\\rEpisode {}\\tAverage Score: {:.6f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "    if i_episode % params['scores_window_size'] == 0:\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.6f}'.format(i_episode, np.mean(scores_window)))\n",
    "    if np.mean(scores_window)>=params['solve_score']:\n",
    "        print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "        #filename = filename.format(hparams['name'], hparams['lr_actor'], hparams['lr_critic'], hparams['batch_size'],\n",
    "        #                           hparams['fc1_units'], hparams['fc2_units'], i_episode-100)\n",
    "        filename = 'checkpoint'\n",
    "        agent.save(filename)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save and plot the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save score\n",
    "df = pd.DataFrame(scores,columns=['scores','average_scores'])\n",
    "df.to_csv('scores/{:s}.csv'.format(filename))\n",
    "\n",
    "# Plot scores\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.axhline(30, color='red', lw=1, alpha=0.3)\n",
    "plt.plot( df.index, 'scores', data=df, color='lime', lw=1, label=\"score\", alpha=0.4)\n",
    "plt.plot( df.index, 'average_scores', data=df, color='green', lw=2, label=\"average score\")\n",
    "# Set labels and legends\n",
    "plt.xlabel('Episode')\n",
    "plt.xlim(0, len(df.index))\n",
    "plt.xticks(50*np.arange(int(len(df.index)/50+1)))\n",
    "plt.ylabel('Score')\n",
    "#plt.yticks(3*np.arange(8))\n",
    "plt.title(filename)\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.legend()\n",
    "# Save figure\n",
    "plt.savefig('docs/plots/{:s}.png'.format(filename), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Watch smart agent\n",
    "\n",
    "If you are skipped training, please specify filename for pre-trained network model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Single '}' encountered in format string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-88a1fbfca0fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load learned model weight. Load 'checkpoint' for optimal model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#filename = 'checkpoint'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Number of episodes to run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MyPrograms/rl/Tennis/agents/maddpg_agent.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/{}_actor{}.pth'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/{}_critic{{}.pth'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;31m#self.agents[0].actor_local.load_state_dict(torch.load('models/{}_actor0.pth'.format(filename)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m#self.agents[0].critic_local.load_state_dict(torch.load('models/{}_critic0.pth'.format(filename)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Single '}' encountered in format string"
     ]
    }
   ],
   "source": [
    "# Speed (False: Real time, True: Fast)\n",
    "train_mode = False\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=train_mode)[brain_name]\n",
    "\n",
    "# Load learned model weight. Load 'checkpoint' for optimal model\n",
    "#filename = 'checkpoint'\n",
    "agent.load(filename)\n",
    "\n",
    "# Number of episodes to run\n",
    "n_episodes = 1\n",
    "\n",
    "# Run loop\n",
    "for i_episode in range(1, n_episodes+1):\n",
    "    # Reset environment\n",
    "    env_info = env.reset(train_mode=train_mode)[brain_name]\n",
    "\n",
    "    # Observe current state\n",
    "    states = env_info.vector_observations\n",
    "\n",
    "    # Reset score and done flag\n",
    "    score = np.zeros(num_agents)\n",
    "\n",
    "    # Episode loop\n",
    "    while True:\n",
    "\n",
    "        # Select action with greedy policy\n",
    "        actions = agent.act(states, add_noise=False)\n",
    "\n",
    "        # Take action\n",
    "        env_info = env.step(actions)[brain_name]\n",
    "\n",
    "        # Observe the next state\n",
    "        next_states = env_info.vector_observations\n",
    "\n",
    "        # Get the reward\n",
    "        rewards = env_info.rewards\n",
    "\n",
    "        # Check if episode is finished\n",
    "        dones = env_info.local_done\n",
    "\n",
    "        # State transition\n",
    "        states = next_states\n",
    "\n",
    "        # Update total score\n",
    "        score += rewards\n",
    "        \n",
    "        # Exit loop if episode finished\n",
    "        if np.any(dones):                                  \n",
    "            break\n",
    "\n",
    "    # Print episode summary\n",
    "    print('Episode {} Score:{:.6f}'.format(i_episode, np.mean(score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, close the environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
